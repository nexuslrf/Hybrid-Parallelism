{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Parallelism Components (Simulated) for Pytorch's Conv2d\n",
    "\n",
    "* 2 modified components: data parallelism & model parallelism.\n",
    "\n",
    "*I'm not very sure of pytorch detailed implementation of `nn.Dataparallel` function, so these components are kind-of upper-level simulations (but indeed work).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: [HyPar: Towards Hybrid Parallelism for Deep Learning Accelerator Array](https://arxiv.org/abs/1901.02067)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dp/mp](fig/dp&mp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.multiprocessing import Queue\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    " \n",
    "Pytorch uses a asynchronized way to invoke cudnn operations automaticly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_parallel_conv2d(nn.Module):\n",
    "    def __init__(self, conv, gpus):\n",
    "        super(model_parallel_conv2d, self).__init__()\n",
    "        self.in_channels = conv.in_channels\n",
    "        self.out_channels = conv.out_channels\n",
    "        self.kernel_size = conv.kernel_size\n",
    "        self.stride = conv.stride\n",
    "        self.padding = conv.padding\n",
    "        self.dilation = conv.dilation\n",
    "        \n",
    "        num_split = len(gpus)\n",
    "        self.gpus = gpus\n",
    "        self.num_split = num_split\n",
    "        \n",
    "        bulk = self.in_channels // num_split\n",
    "        self.in_channels_split = [bulk for i in range(num_split-1)]\n",
    "        self.in_channels_split.append(self.in_channels-(num_split-1)*bulk)\n",
    "        self.convs = nn.ModuleList()\n",
    "        offset = 0\n",
    "        bias = False\n",
    "        for i in range(num_split):\n",
    "            if i==num_split-1:\n",
    "                bias=True\n",
    "            conv_split = nn.Conv2d(self.in_channels_split[i],\n",
    "                             self.out_channels,\n",
    "                             self.kernel_size,\n",
    "                             self.stride,\n",
    "                             self.padding,\n",
    "                             self.dilation,\n",
    "                             bias=bias)\n",
    "            conv_split.weight = nn.Parameter(\n",
    "                conv.weight[:,offset:offset+self.in_channels_split[i],:,:].cuda(gpus[i]))\n",
    "            if bias:\n",
    "                conv_split.bias = nn.Parameter(conv.bias.cuda(gpus[i]))\n",
    "            self.convs.append(conv_split)\n",
    "            offset+= self.in_channels_split[i]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature_list = [None] * self.num_split\n",
    "        parallel_type = ''\n",
    "        if type(x)!=tuple:\n",
    "            inputs = [x.cuda(g) for g in self.gpus]\n",
    "        else:\n",
    "            inputs, parallel_type = x\n",
    "        offset = 0\n",
    "        if parallel_type == 'dp':\n",
    "            for i in range(self.num_split):\n",
    "                in_slice = \\\n",
    "                    torch.cat([\n",
    "                        inputs[k][:,\n",
    "                                  offset:offset+self.in_channels_split[i],\n",
    "                                  :,:].cuda(self.gpus[i])\n",
    "                        for k in range(self.num_split)], 0)\n",
    "                feature_list[i] = self.convs[i](in_slice)\n",
    "                offset+= self.in_channels_split[i]\n",
    "        else:\n",
    "            for i in range(self.num_split):\n",
    "                feature_list[i] = \\\n",
    "                    self.convs[i](inputs[i][:,offset:offset+self.in_channels_split[i],:,:])\n",
    "                offset+= self.in_channels_split[i]\n",
    "        \n",
    "        tmp_out = sum([f.cuda(self.gpus[0]) for f in feature_list])\n",
    "        for i in range(self.num_split):\n",
    "            feature_list[i] = tmp_out.cuda(self.gpus[i])\n",
    "        return feature_list, 'mp'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_parallel_conv2d(nn.Module):\n",
    "    def __init__(self, conv, gpus):\n",
    "        super(data_parallel_conv2d, self).__init__()\n",
    "        self.in_channels = conv.in_channels\n",
    "        self.out_channels = conv.out_channels\n",
    "        self.kernel_size = conv.kernel_size\n",
    "        self.stride = conv.stride\n",
    "        self.padding = conv.padding\n",
    "        self.dilation = conv.dilation\n",
    "        \n",
    "        self.gpus = gpus\n",
    "        self.convs = nn.ModuleList([\n",
    "            copy.deepcopy(conv).cuda(i) for i in gpus\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        parallel_type = ''\n",
    "        if type(x)!=tuple:\n",
    "            inputs = nn.parallel.scatter(x, self.gpus)\n",
    "        else:\n",
    "            inputs, parallel_type = x\n",
    "#         if parallel_type == 'dp':\n",
    "        if parallel_type == 'mp':\n",
    "            bs = inputs[0].shape[0]\n",
    "            bulk = bs//len(self.gpus)\n",
    "            outputs = [self.convs[i](inputs[i][i*bulk:(i+1)*bulk,:,:,:]) \n",
    "                       for i in range(len(self.gpus)-1)]\n",
    "            outputs.append(self.convs[-1](\n",
    "                inputs[-1][bulk*(len(self.gpus)-1):,:,:,:]))\n",
    "        else:\n",
    "            outputs = [self.convs[i](inputs[i]) for i in range(len(inputs))]\n",
    "        return outputs, 'dp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](fig/hypar_connection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = torch.randn(16,8,7,7)\n",
    "conv1 = nn.Conv2d(8,8,3).cuda(2)\n",
    "conv2 = nn.Conv2d(8,8,3).cuda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.9450, device='cuda:2', grad_fn=<SumBackward0>),\n",
       " tensor(-36.1029, device='cuda:2', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv1(in_data.cuda(2))\n",
    "b = conv2(a)\n",
    "a_sum = a.sum()\n",
    "b_sum = b.sum()\n",
    "a_sum, b_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.6203, device='cuda:2'), tensor(-1466.1299, device='cuda:2'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_sum.backward()\n",
    "conv1.weight.grad.sum(), conv2.weight.grad.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dp-dp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_conv1 = data_parallel_conv2d(conv1, [0,1])\n",
    "dp_conv2 = data_parallel_conv2d(conv2, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.9450, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " tensor(-36.1029, device='cuda:0', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_a = dp_conv1(in_data.cuda(0))\n",
    "dp_b = dp_conv2(dp_a)\n",
    "dp_a_sum = (dp_a[0][0] + dp_a[0][1].cuda(0)).sum()\n",
    "dp_b_sum = (dp_b[0][0] + dp_b[0][1].cuda(0)).sum()\n",
    "dp_a_sum, dp_b_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.6203, device='cuda:0'), tensor(-1466.1299, device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_b_sum.backward()\n",
    "dp_conv1.convs[0].weight.grad.sum() + dp_conv1.convs[1].weight.grad.sum().cuda(0),\\\n",
    "    dp_conv2.convs[0].weight.grad.sum() + dp_conv2.convs[1].weight.grad.sum().cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mp-mp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_conv1 = model_parallel_conv2d(conv1, [0,1])\n",
    "mp_conv2 = model_parallel_conv2d(conv2, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.9450, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " tensor(-36.1029, device='cuda:0', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_a = mp_conv1(in_data.cuda(0))\n",
    "mp_b = mp_conv2(mp_a)\n",
    "(mp_a[0][0]).sum(), (mp_b[0][0]).sum(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mp_b[0][0]).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.6203, device='cuda:0'), tensor(-1466.1299, device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mp_conv1.convs[0].weight.grad.sum()+mp_conv1.convs[1].weight.grad.sum().cuda(0)),\\\n",
    "    (mp_conv2.convs[0].weight.grad.sum() + mp_conv2.convs[1].weight.grad.sum().cuda(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mp-dp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_conv1 = model_parallel_conv2d(conv1, [0,1])\n",
    "dp_conv2 = data_parallel_conv2d(conv2, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_a = mp_conv1(in_data.cuda(0))\n",
    "dp_b = dp_conv2(mp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.9450, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " tensor(-36.1029, device='cuda:0', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_b_sum = (dp_b[0][0]+dp_b[0][1].cuda(0)).sum()\n",
    "(mp_a[0][0]).sum(), dp_b_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_b_sum.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.6203, device='cuda:0'), tensor(-1466.1298, device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mp_conv1.convs[0].weight.grad.sum()+mp_conv1.convs[1].weight.grad.sum().cuda(0)),\\\n",
    "    (dp_conv2.convs[0].weight.grad.sum() + dp_conv2.convs[1].weight.grad.sum().cuda(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dp-mp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_conv1 = data_parallel_conv2d(conv1, [0,1])\n",
    "mp_conv2 = model_parallel_conv2d(conv2, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_a = dp_conv1(in_data.cuda(0))\n",
    "mp_b = mp_conv2(dp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.9450, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " tensor(-36.1029, device='cuda:0', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dp_a[0][0]+dp_a[0][1].cuda(0)).sum(), (mp_b[0][0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mp_b[0][0]).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.6203, device='cuda:0'), tensor(-1466.1299, device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dp_conv1.convs[0].weight.grad.sum()+dp_conv1.convs[1].weight.grad.sum().cuda(0)),\\\n",
    "    (mp_conv2.convs[0].weight.grad.sum() + mp_conv2.convs[1].weight.grad.sum().cuda(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
